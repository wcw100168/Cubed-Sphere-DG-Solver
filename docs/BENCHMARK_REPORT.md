# Cubed Sphere Solver 效能基準測試報告 (Benchmark Report)

| 更新日期 | 2026/02/01 |
| :--- | :--- |
| **測試環境** | Google Colab (Linux) |
| **硬體規格** | GPU: NVIDIA T4 / CPU: Intel Xeon |
| **比較對象** | NumPy (CPU) vs JAX (GPU) |

## 1. 測試摘要

本報告旨在評估求解器在不同網格解析度 ($N$) 下的效能表現。測試結果顯示，**JAX (GPU)** 後端在大規模運算中展現出顯著優勢，最高可達 **4.13 倍** 的加速。

## 2. 基準測試結果 (Summary Table)

| N (Grid Size) | NumPy (s) | JAX (GPU) (s) | Speedup (x) | 備註 |
| :--- | :--- | :--- | :--- | :--- |
| **32** | 0.5992 | 17.4830 | 0.03x | GPU 初始化與編譯成本佔主導 |
| **64** | 4.2511 | 19.4447 | 0.22x | 兩者效能逐漸接近 |
| **128** | **94.1779** | **22.7688** | **4.14x** | **GPU 優勢顯著爆發** |

> *註：時間包含 JIT 編譯與資料傳輸時間，模擬真實使用情境。*

## 3. 結果分析 (Performance Analysis)

### 3.1 小規模網格 ($N=32, 64$)：CPU 勝出
* **現象**：在 $N=32$ 時，JAX 顯著慢於 NumPy (0.03x)。
* **原因**：JAX 首次執行需要進行 XLA (JIT) 編譯，這通常耗時 10~20 秒。當問題規模較小，實際運算時間極短（毫秒級），編譯時間成為主要瓶頸。此外，GPU 核心未能被填滿，處於「飢餓」狀態。
* **建議**：開發、除錯與小規模測試建議使用 **NumPy** 後端。

### 3.2 大規模網格 ($N=128$)：GPU 宰制
* **現象**：在 $N=128$ 時，情勢逆轉，JAX 比 NumPy 快了 **4 倍以上**。
* **原因**：
    1.  **運算密度增加**：網格點數量增加 16 倍 ($32^2 \to 128^2$)，足以填滿 GPU 的數千個 CUDA 核心。
    2.  **編譯成本稀釋**：隨著運算量（時間步長增加）變大，初始的編譯時間佔比大幅下降。
* **建議**：高解析度模擬 ($N \ge 128$) 強烈建議使用 **JAX** 後端。

## 4. 結論

本專案的「雙後端架構」成功涵蓋了不同使用情境：
* **NumPy**: 適合 $N < 64$ 的快速迭代與開發。
* **JAX**: 適合 $N \ge 128$ 的高效能生產環境模擬。

若進一步將網格提升至 $N=256$ 或更高，預期加速倍率將進一步擴大。